import cv2
from ultralytics import YOLO
import os
import numpy as np
import time

# Ensure we are working with the correct directory
script_dir = os.path.dirname(os.path.realpath(__file__))  # Get directory of the script
model_path = os.path.join(script_dir, "overheadbest.pt")

# Check if model file exists
if not os.path.exists(model_path):
    print(f"Error: Model file '{model_path}' not found!")
    exit()

# Load the YOLO model
model = YOLO(model_path)

# Access the webcam
cap = cv2.VideoCapture(0)  # Try changing the index if the webcam does not open

if not cap.isOpened():
    print("Error: Could not open webcam.")
    exit()

# Dictionary to track target confidence over time
target_confidence = {}
locked_targets = {}  # Dictionary to store locked target positions

while True:
    # Capture frame-by-frame
    ret, frame = cap.read()

    if not ret:
        print("Error: Could not read frame from webcam.")
        break

    # Perform detection on the frame
    results = model.predict(frame)

    # Define classifications
    targets = ["earth", "saturn"]

    # Annotate frame with detection results
    annotated_frame = frame.copy()

    # Access the results (boxes, labels, etc.)
    if len(results) > 0:
        boxes = results[0].boxes  # Accessing the first result
        labels = results[0].names  # Accessing the labels
    else:
        boxes = []
        labels = []

    # Print detected labels to verify the output
    detected_labels = [labels[int(box.cls)] for box in boxes]
    print("Detected labels:", detected_labels)

    # List of target centers, bottom, top, and center objects
    bottom_object = None
    top_object = None
    center_object = None
    target_centers = []

    # Find the "bottom", "top", and "center" objects and target centers
    for i, box in enumerate(boxes):
        label = labels[int(box.cls)]  # Get the class label
        x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())
        confidence = box.conf  # Get the confidence score

        # Get the center of the bounding box
        box_center = ((x1 + x2) // 2, (y1 + y2) // 2)

        if label == "bottom":  # Look for the object labeled "bottom"
            bottom_object = box_center
        elif label == "top":  # Look for the object labeled "top"
            top_object = box_center
        elif label == "center":  # Look for the object labeled "center"
            center_object = box_center
        elif label in targets:
            if label in locked_targets:
                # Use the locked position if the target is locked
                target_centers.append((locked_targets[label], label))
            else:
                target_centers.append((box_center, label))

                # Track confidence over time
                if label not in target_confidence:
                    target_confidence[label] = {'start_time': time.time(), 'confidence': confidence}
                else:
                    if confidence > 0.90:
                        if time.time() - target_confidence[label]['start_time'] >= 2:
                            target_confidence[label]['locked'] = True
                            locked_targets[label] = box_center  # Lock the target position
                        else:
                            target_confidence[label]['confidence'] = confidence
                    else:
                        target_confidence[label] = {'start_time': time.time(), 'confidence': confidence}

    # If there is no object labeled "bottom" or "top", display the frame without annotations
    if not bottom_object or not top_object:
        cv2.imshow("YOLO Detection", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
        continue

    # Draw a line from the 'bottom' object to the 'top' object
    cv2.line(annotated_frame, bottom_object, top_object, (0, 255, 255), 2)  # Yellow line

    # Calculate direction based on relative positions of bottom and top objects
    dx = top_object[0] - bottom_object[0]  # Difference in x
    dy = top_object[1] - bottom_object[1]  # Difference in y

    # Determine the direction based on the position of 'top' relative to 'bottom'
    if abs(dy) > abs(dx):  # North or South direction
        if dy < 0:
            direction = "North"  # Top is above Bottom
        else:
            direction = "South"  # Bottom is below Top
    else:  # East or West direction
        if dx > 0:
            direction = "East"  # Top is to the right of Bottom
        else:
            direction = "West"  # Top is to the left of Bottom

    # Prepare the text to display the direction on the frame
    direction_text = f"Direction: {direction}"

    # Display the direction on the frame
    cv2.putText(annotated_frame, direction_text, (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)  # White text for direction

    # Calculate the angle (in degrees) of the line between 'bottom' and 'top'
    angle_rad = np.arctan2(dy, dx)  # Angle in radians
    angle_deg = np.degrees(angle_rad)  # Convert angle to degrees

    # Prepare the text to display the angle on the frame
    angle_text = f"Angle: {angle_deg:.2f}Â°"

    # Display the angle on the frame
    cv2.putText(annotated_frame, angle_text, (20, 80), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)  # White text for angle

    # Find the nearest target
    nearest_target = None
    min_distance = float('inf')
    for center, label in target_centers:
        distance = np.linalg.norm(np.array(center) - np.array(bottom_object))
        if distance < min_distance:
            min_distance = distance
            nearest_target = center

    # Calculate the angle to the nearest target
    if nearest_target:
        target_dx = nearest_target[0] - bottom_object[0]
        target_dy = nearest_target[1] - bottom_object[1]
        target_angle_rad = np.arctan2(target_dy, target_dx)
        target_angle_deg = np.degrees(target_angle_rad)

        # Determine the rotation direction
        angle_diff = target_angle_deg - angle_deg
        if angle_diff > 180:
            angle_diff -= 360
        elif angle_diff < -180:
            angle_diff += 360

        if abs(angle_diff) <= 20:
            rotation_text = "Go Forward"
        elif angle_diff > 0:
            rotation_direction = "R"
            rotation_text = f"Rotate: {rotation_direction}"
        else:
            rotation_direction = "L"
            rotation_text = f"Rotate: {rotation_direction}"

        # Display the rotation direction or "Go Forward" on the frame
        cv2.putText(annotated_frame, rotation_text, (20, 120), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 255, 255), 3, cv2.LINE_AA)  # White text for rotation

    # Draw bounding boxes and labels for the 'bottom', 'top', 'center', and targets
    for i, box in enumerate(boxes):
        label_in_box = labels[int(box.cls)]
        x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())
        confidence = box.conf  # Get the confidence score

        if label_in_box == "bottom":
            color = (0, 255, 255)  # Yellow for bottom
            text = f"Bottom ({confidence.item():.2f})"
        elif label_in_box == "top":
            color = (255, 0, 255)  # Magenta for top
            text = f"Top ({confidence.item():.2f})"
        elif label_in_box == "center":
            color = (0, 255, 255)  # Cyan for center
            text = f"Center ({confidence.item():.2f})"
        elif label_in_box in targets:
            if label_in_box in target_confidence and target_confidence[label_in_box].get('locked', False):
                continue  # Skip drawing for locked targets
            else:
                color = (0, 255, 0)  # Green for targets
                text = f"{label_in_box.capitalize()} ({confidence.item():.2f})"
        else:
            continue

        cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)
        cv2.putText(annotated_frame, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)

    # Draw locked targets
    for label, position in locked_targets.items():
        x, y = position
        color = (0, 0, 255)  # Red for locked targets
        text = f"{label.capitalize()} (Locked)"
        cv2.putText(annotated_frame, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)
        cv2.circle(annotated_frame, position, 5, color, -1)

    # Resize the window
    cv2.namedWindow("YOLO Detection", cv2.WINDOW_NORMAL)
    cv2.resizeWindow("YOLO Detection", 1280, 720)  # Resize to 16:9 aspect ratio

    # Display the frame with detections
    cv2.imshow("YOLO Detection", annotated_frame)
    cv2.waitKey(1)  # Add a small delay to allow the window to open

    # Break the loop if 'q' is pressed
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the webcam and close the window
cap.release()
cv2.destroyAllWindows()